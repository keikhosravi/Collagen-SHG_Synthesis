{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import shutil, sys  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import Reconstruction_dataset as dt\n",
    "import model_4_o as mdo\n",
    "import model_ResUGAN as md\n",
    "import numpy as np\n",
    "import os, glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets, utils, models\n",
    "import pandas as pd\n",
    "import math\n",
    "import torchvision\n",
    "from skimage import io, transform, img_as_float, exposure\n",
    "import cv2\n",
    "from tkinter.filedialog import askopenfilename, askopenfilenames\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import imagej\n",
    "#ij=imagej.init(r'C:\\fiji-win64\\Fiji.app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_names():\n",
    "    \n",
    "    filenames = askopenfilenames()\n",
    "    \n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_padding(image, stride, patch_size):\n",
    "    \n",
    "    y_size = image.shape[0]\n",
    "    x_size = image.shape[1]\n",
    "    (dy,my)=divmod(y_size-patch_size,stride)\n",
    "    (dx,mx)=divmod(x_size-patch_size,stride)\n",
    "    dif_y=stride-my\n",
    "    dif_x=stride-mx\n",
    "    if (my > 0 ):\n",
    "        \n",
    "        new_y_size = y_size + dif_y\n",
    "        pad_y = dif_y\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        new_y_size = y_size\n",
    "        pad_y = my\n",
    "    if (mx > 0 ):   \n",
    "        new_x_size = x_size + dif_x\n",
    "        pad_x = dif_x\n",
    "    else:\n",
    "        new_x_size = x_size\n",
    "        pad_x = mx\n",
    "    \n",
    "    image_resized = resize(image, (new_y_size, new_x_size))\n",
    "    padded_image= cv2.copyMakeBorder(image,0,pad_y,0,pad_x,cv2.BORDER_CONSTANT,value=0)\n",
    "    \n",
    "    return (padded_image,pad_y,pad_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_num_calculator(image,patch_size, stride):\n",
    "    \n",
    "    y_size = image.shape[0]\n",
    "    x_size = image.shape[1]\n",
    "\n",
    "    rows_patch_num = int(math.floor((image.shape[0]-patch_size)/stride)+1)\n",
    "    culs_patch_num = int(math.floor((image.shape[1]-patch_size)/stride)+1)\n",
    "\n",
    "    return (rows_patch_num,culs_patch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_minibatch(image, stride,patch_size, device,rows_patch_num,culs_patch_num, unpadd_patch, HE_name):\n",
    "    \n",
    "    path = os.getcwd()  \n",
    "    HEpatch_path1 =os.path.join(path, \"Patches\", \"HEpatches\")\n",
    "    HEpatch_path =os.path.join(HEpatch_path1, \"HEpatches\")\n",
    "\n",
    "    if ( os.path.exists(HEpatch_path) != True):\n",
    "            os.mkdir(HEpatch_path)\n",
    "            \n",
    "    output_path1 =os.path.join(path, \"Patches\", \"HPan-Ade170Sur-01_101\")\n",
    "    img_name = HE_name.split('/')[-1].split('.tif')[0]\n",
    "    output_path =os.path.join(output_path1, img_name)\n",
    "\n",
    "    if ( os.path.exists(output_path) != True):\n",
    "            os.mkdir(output_path) \n",
    "                                  \n",
    "    config_file=os.path.join(output_path, \"TileConfiguration.txt\")\n",
    "    config = open(config_file,\"w+\")\n",
    "    openning_text = \"# Define the number of dimensions we are working on\" + \"\\n\" + \"dim = 2\" + \"\\n\\n\" + \"# Define the image coordinates\"+ \"\\n\"\n",
    "    config.write(openning_text)\n",
    "    to_be_cropped_row=[]\n",
    "    to_be_cropped_col=[]\n",
    "    for i in range(rows_patch_num):\n",
    "        for j in range(culs_patch_num):\n",
    "\n",
    "             HEpatch=image[i*stride : i*stride + patch_size, j*stride : j*stride + patch_size, :]\n",
    "             col = i*stride - unpadd_patch\n",
    "             row = j*stride - unpadd_patch\n",
    "             image_name = img_name + \"_SHGpatch_\" + i.__str__() +\"_\" + j.__str__() +\".tif\"\n",
    "             image_path=os.path.join(HEpatch_path, image_name)\n",
    "             coordinates = \"; ;\" + \" (\" + row.__str__()  + \",\" + col.__str__()  + \")\" + \"\\n\"\n",
    "             config_text = image_name + coordinates\n",
    "             config.write(config_text)\n",
    "             io.imsave(image_path,HEpatch)\n",
    "             if (i == rows_patch_num-1):\n",
    "                to_be_cropped_row.append(image_name)\n",
    "             if (j == culs_patch_num-1):\n",
    "                to_be_cropped_col.append(image_name)\n",
    "    config.close()\n",
    "    return (HEpatch_path,output_path, to_be_cropped_row, to_be_cropped_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print gpu\n",
    "torch.cuda.set_device(0)\n",
    "currentDevice = torch.cuda.current_device()\n",
    "print(\"Current GPU: \" + str(currentDevice))\n",
    "print(str(torch.cuda.device_count()))\n",
    "print(str(torch.cuda.get_device_capability(currentDevice)))\n",
    "print(torch.__version__)\n",
    "\n",
    "USE_GPU = 1\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "path = os.path.join(cwd, 'Saved model', 'GAN_output', 'trained_generator.pth')\n",
    "\n",
    "# path = os.path.join(cwd, 'Best model', 'encoderresinfo_0414.pth')\n",
    "state_dict = torch.load(path, map_location=torch.device('cuda:0'))\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "# load params\n",
    "# # model = md.Net()\n",
    "model = md.GeneratorUNet()\n",
    "# model.load_state_dict(new_state_dict)\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_to_network(HEpatch_path, model, minibatch_size, device, output_path, patch_size,to_be_cropped_row, to_be_cropped_col,pad_y,pad_x):\n",
    "   \n",
    "    image_datasets = datasets.ImageFolder(HEpatch_path, transform = transforms.ToTensor())\n",
    "    dataloader = DataLoader(image_datasets, batch_size=minibatch_size,\n",
    "                        shuffle=False, num_workers=0)\n",
    "    k=0\n",
    "    l=0\n",
    "    for  inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                network_output = model(inputs)\n",
    "                \n",
    "                \n",
    "                for i in range(network_output.shape[0]):\n",
    "                    \n",
    "                        patch1 = network_output[i,:, :, :].data.cpu().numpy().transpose(1,2,0).reshape(patch_size , patch_size)\n",
    "                        patch = exposure.adjust_gamma(patch1, 0.9)\n",
    "                        img_file_name = image_datasets.imgs[k*minibatch_size+i][0]\n",
    "                        img_name = img_file_name.split('\\\\')[-1]\n",
    "                        image_path=os.path.join(output_path, img_name)\n",
    "                        data = 255 * patch # Now scale by 255\n",
    "                        img = data.astype(np.uint8)\n",
    "                        ret,img = cv2.threshold(img,40,255,cv2.THRESH_TOZERO)\n",
    "\n",
    "                        if (img_name in to_be_cropped_col):\n",
    "                            img=img[:,0:patch_size-pad_x]\n",
    "                        if (img_name in to_be_cropped_row):\n",
    "                            img=img[0:patch_size-pad_y,:]\n",
    "                            \n",
    "                        cv2.imwrite(image_path,img)\n",
    "                        l=l+1\n",
    "                k=k+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpadd_patch=0\n",
    "stride=96\n",
    "patch_size= 128\n",
    "minibatch_size = 128\n",
    "HE_names = get_image_names()\n",
    "for i in range(HE_names.__len__()):\n",
    "    HE_name = ''.join(HE_names[i])\n",
    "    HE_image=io.imread(HE_name)\n",
    "    (padded_image,pad_y,pad_x)=image_padding(HE_image, stride, patch_size)\n",
    "\n",
    "    (rows_patch_num,culs_patch_num) = patch_num_calculator(padded_image,patch_size, stride)\n",
    "    (HEpatch_path,output_path, to_be_cropped_row, to_be_cropped_col) = image_to_minibatch(padded_image, \n",
    "                                                                                          stride,patch_size, \n",
    "                                                                                          device,rows_patch_num,\n",
    "                                                                                          culs_patch_num,unpadd_patch,\n",
    "                                                                                          HE_name)\n",
    "    minibatch_to_network(\"F:\\HE_SHG_project\\Patches\\HEpatches\", model, minibatch_size, device, output_path, \n",
    "                         patch_size,to_be_cropped_row, to_be_cropped_col,pad_y,pad_x)\n",
    "\n",
    "    shutil.rmtree(HEpatch_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpadd_patch=0\n",
    "stride=96\n",
    "patch_size= 128\n",
    "minibatch_size = 128\n",
    "HE_names = get_image_names()\n",
    "save_path= r'F:\\HE_SHG_project\\stictched synthesized\\New_breast'\n",
    "for i in range(HE_names.__len__()):\n",
    "    HE_name = ''.join(HE_names[i])\n",
    "    HE_image=io.imread(HE_name)\n",
    "    (padded_image,pad_y,pad_x)=image_padding(HE_image, stride, patch_size)\n",
    "\n",
    "    (rows_patch_num,culs_patch_num) = patch_num_calculator(padded_image,patch_size, stride)\n",
    "    (HEpatch_path,output_path, to_be_cropped_row, to_be_cropped_col) = image_to_minibatch(padded_image, \n",
    "                                                                                          stride,patch_size, \n",
    "                                                                                          device,rows_patch_num,\n",
    "                                                                                          culs_patch_num,unpadd_patch,\n",
    "                                                                                          HE_name)\n",
    "    minibatch_to_network(\"F:\\HE_SHG_project\\Patches\\HEpatches\", model, minibatch_size, device, output_path, \n",
    "                         patch_size,to_be_cropped_row, to_be_cropped_col,pad_y,pad_x)\n",
    "    args = {'type': 'Positions from file', 'order': 'Defined by TileConfiguration', 'directory':output_path, \n",
    "            'ayout_file': 'TileConfiguration.txt', 'fusion_method': 'Linear Blending', 'regression_threshold': '0.30', \n",
    "            'max/avg_displacement_threshold':'2.50', 'absolute_displacement_threshold': '3.50', \n",
    "            'computation_parameters': 'Save memory (but be slower)', 'image_output': 'Write to disk', \n",
    "            'output_directory': save_path}\n",
    "    plugin = \"Grid/Collection stitching\"\n",
    "     \n",
    "    ij.py.run_plugin(plugin, args)\n",
    "    shutil.rmtree(HEpatch_path)\n",
    "    shutil.rmtree(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HE_names = get_image_names()\n",
    "output_path = \"F:\\\\HE_SHG_project\\\\stictched synthesized\\\\SA_stroma\\\\Thresholded\\\\\"\n",
    "for i in range(HE_names.__len__()):\n",
    "    HE_name = ''.join(HE_names[i])\n",
    "    HE_image=io.imread(HE_name)\n",
    "    ret,img = cv2.threshold(HE_image,40,200,cv2.THRESH_TOZERO)\n",
    "    img_name = HE_name.split('\\\\')[-1]\n",
    "    image_path=os.path.join(output_path, img_name)\n",
    "                       \n",
    "    cv2.imwrite(image_path,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    image_path=os.path.join(output_path, img_name)\n",
    "\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"F:\\\\HE_SHG_project\\\\stictched synthesized\\\\SA_stroma\\\\Thresholded\\\\\"\n",
    "image_path=os.path.join(output_path, img_name)\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
